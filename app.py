import streamlit as st
import json
import os
import datetime
import io
from gtts import gTTS
from openai import OpenAI
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from aiortc.contrib.media import MediaRecorder
from pathlib import Path
from streamlit_mic_recorder import mic_recorder

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –í–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
QUESTIONS = [
    "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–µ–±–µ.",
    "–ö–∞–∫–æ–≤—ã –≤–∞—à–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã?",
    "–û–ø–∏—à–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, –Ω–∞–¥ –∫–æ—Ç–æ—Ä—ã–º –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏.",
    "–ü–æ—á–µ–º—É –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å —ç—Ç—É –¥–æ–ª–∂–Ω–æ—Å—Ç—å?",
    "–ì–¥–µ –≤—ã –≤–∏–¥–∏—Ç–µ —Å–µ–±—è —á–µ—Ä–µ–∑ –ø—è—Ç—å –ª–µ—Ç?"
]

# –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
if "question_index" not in st.session_state:
    st.session_state.question_index = 0
if "transcriptions" not in st.session_state:
    st.session_state.transcriptions = []
if "video_path" not in st.session_state:
    st.session_state.video_path = None

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∑–∞–ø–∏—Å–µ–π
REC_DIR = Path("recordings")
REC_DIR.mkdir(exist_ok=True)

if "rec_filename" not in st.session_state:
    prefix = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    st.session_state.rec_filename = REC_DIR / f"{prefix}.mp4"

out_path = st.session_state.rec_filename

# –¢–µ–∫—Å—Ç –≤ —Ä–µ—á—å
def text_to_speech(text, filename):
    try:
        tts = gTTS(text=text, lang="ru")
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ Whisper
def whisper_stt(question_index):
    audio = mic_recorder(
        start_prompt="üéôÔ∏è –ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç",
        stop_prompt="‚èπÔ∏è –°—Ç–æ–ø",
        format="webm",
        key=f"whisper_{question_index}"
    )
    if audio:
        audio_bio = io.BytesIO(audio["bytes"])
        audio_bio.name = "audio.webm"
        try:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_bio,
                language="ru"
            )
            return transcription.text
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"
    return None

# –§–∞–±—Ä–∏–∫–∞ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ+–∞—É–¥–∏–æ
def in_recorder_factory():
    return MediaRecorder(str(out_path), format="mp4")

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.title("–¢—Ä–µ–Ω–∞–∂—ë—Ä —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π")

ctx = webrtc_streamer(
    key="interview-recorder",
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints={"video": True, "audio": True},
    in_recorder_factory=in_recorder_factory,
)

# –ó–∞–¥–∞—ë–º –≤–æ–ø—Ä–æ—Å—ã
if st.session_state.question_index < len(QUESTIONS):
    current_question = QUESTIONS[st.session_state.question_index]
    st.write(f"–í–æ–ø—Ä–æ—Å {st.session_state.question_index + 1}: {current_question}")

    audio_file = f"question_{st.session_state.question_index}.mp3"
    if text_to_speech(current_question, audio_file):
        with open(audio_file, "rb") as f:
            st.audio(f.read(), format="audio/mp3", autoplay=True)

    transcription = whisper_stt(st.session_state.question_index)
    if transcription:
        st.session_state.transcriptions.append({
            "question": current_question,
            "transcription": transcription,
            "timestamp": datetime.datetime.now().isoformat()
        })

        st.session_state.question_index += 1
        if os.path.exists(audio_file):
            os.remove(audio_file)
        st.rerun()

# –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ
if st.session_state.question_index >= len(QUESTIONS) and ctx and not ctx.state.playing:
    if out_path.exists() and out_path.stat().st_size > 100_000:
        st.subheader("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        for item in st.session_state.transcriptions:
            st.write(f"**–í–æ–ø—Ä–æ—Å:** {item['question']}")
            st.write(f"**–í–∞—à –æ—Ç–≤–µ—Ç:** {item['transcription']}")
            st.write(f"**–í—Ä–µ–º—è:** {item['timestamp']}")
            st.write("---")

        st.subheader("–í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å —Å –∞—É–¥–∏–æ")
        st.video(str(out_path))
        st.download_button(
            "–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (MP4)",
            data=out_path.read_bytes(),
            file_name=out_path.name,
            mime="video/mp4",
        )

        results = {
            "–¥–∞—Ç–∞_–∏–Ω—Ç–µ—Ä–≤—å—é": datetime.datetime.now().isoformat(),
            "–≤–æ–ø—Ä–æ—Å—ã": st.session_state.transcriptions
        }
        json_filename = f"—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã_–∏–Ω—Ç–µ—Ä–≤—å—é_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_filename, "w") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        with open(json_filename, "rb") as f:
            st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)", f, json_filename, "application/json")

        if st.button("–ù–∞—á–∞—Ç—å –Ω–æ–≤–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é"):
            st.session_state.question_index = 0
            st.session_state.transcriptions = []
            st.session_state.video_path = None
            st.session_state.rec_filename = REC_DIR / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
            st.rerun()
