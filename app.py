import streamlit as st
import json
import os
import datetime
import time
import uuid
import subprocess
from pathlib import Path
from gtts import gTTS
from openai import OpenAI
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from aiortc.contrib.media import MediaRecorder

# ========== CONFIG ==========
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
QUESTIONS = [
    "–ö–∞–∫ —Ç—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å —Å–≤–æ–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞ –æ—Ç 1 –¥–æ 10?",
    "–ö–∞–∫ —Ç—ã –æ–±—ã—á–Ω–æ —Å–Ω–∏–º–∞–µ—à—å —Å—Ç—Ä–µ—Å—Å: –µ–¥–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–µ –∏–≥—Ä—ã?",
]

REC_DIR = Path("recordings")
REC_DIR.mkdir(exist_ok=True)

# ========== SESSION STATE INITIALIZATION ==========
defaults = {
    "start_interview": False,
    "questions_started": False,
    "question_index": 0,
    "question_audio_played": False,
    "answer_start_time": None,
    "timestamps": [],
    "recording_started_at": None,
    "video_ready": False,
    "video_filename": REC_DIR / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4",
    "transcriptions": [],
    "recorder_stopped": False,
    "processing_started": False,
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ========== HELPERS ==========
def text_to_speech(text, filename):
    try:
        tts = gTTS(text=text, lang="ru")
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

def whisper_stt(audio_path: Path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
        return transcription.text
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {str(e)}"

def ffmpeg_available():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except Exception:
        return False

def cut_audio_segment(video_path: Path, start: float, end: float, output_path: Path):
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", str(video_path),
            "-ss", f"{start}",
            "-to", f"{end}",
            "-vn",
            "-acodec", "libmp3lame",
            str(output_path)
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except subprocess.CalledProcessError as e:
        stderr = e.stderr.decode() if e.stderr else str(e)
        st.error(f"FFmpeg error while cutting audio: {stderr}")
        return False

# ========== UI ==========
st.title("interview-psychologist")

if not st.session_state.start_interview:
    st.info(
        "üìπ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n\n"
        "1. –ù–∞–∂–º–∏—Ç–µ **–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é** ‚Äî —ç—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –∫–∞–º–µ—Ä—É –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –Ω–∞—á–Ω—ë—Ç –∑–∞–ø–∏—Å—å.\n"
        "2. –ù–∞–∂–º–∏—Ç–µ **‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã** ‚Äî –≤–æ–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –∑–∞—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –≤—Å–ª—É—Ö.\n"
        "3. –ü–æ—Å–ª–µ –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç–≤–µ—á–∞–π—Ç–µ; –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–∂–º–∏—Ç–µ **–î–∞–ª–µ–µ**.\n"
        "4. –ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É ¬´**STOP**¬ª –ø–æ–¥ –≤–∏–¥–µ–æ, –∑–∞—Ç–µ–º **–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**.\n"
        "5. –í—ã –ø–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É.\n\n"
        "**–í–∞–∂–Ω–æ:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –±—Ä–∞—É–∑–µ—Ä —Ä–∞–∑—Ä–µ—à–∏–ª –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∏ –∫–∞–º–µ—Ä–µ."
    )
    if st.button("üé¨ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é"):
        st.session_state.start_interview = True
        st.rerun()
else:
    video_filename_path = str(st.session_state.video_filename)

    # Use 'sendonly' for video and 'sendrecv' for audio to prevent issues
    video_ctx = webrtc_streamer(
    key="interview-video",
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints={
        "video": {"width": 640, "height": 480, "frameRate": 15},
        "audio": True
    },
    # ‚úÖ FIXED: Record the outgoing (looped-back) stream which has audio.
    out_recorder_factory=lambda: MediaRecorder(video_filename_path, format="mp4"),
    )

    if video_ctx.state.playing and st.session_state.recording_started_at is None:
        st.session_state.recording_started_at = time.time()
        st.success("–ó–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –Ω–∞—á–∞–ª–∞—Å—å.")

    # Show "Start Questions" button only when video is playing
    if video_ctx.state.playing and not st.session_state.questions_started and not st.session_state.video_ready:
        if st.button("‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã"):
            st.session_state.questions_started = True
            st.session_state.question_audio_played = False
            st.rerun()

    if st.session_state.questions_started and not st.session_state.video_ready:
        if st.session_state.question_index < len(QUESTIONS):
            q_idx = st.session_state.question_index
            current_question = QUESTIONS[q_idx]
            st.write(f"–í–æ–ø—Ä–æ—Å {q_idx + 1}: {current_question}")

            if not st.session_state.question_audio_played:
                tts_file = REC_DIR / f"q_{q_idx}_{uuid.uuid4().hex}.mp3"
                if text_to_speech(current_question, str(tts_file)):
                    with open(tts_file, "rb") as f:
                        st.audio(f.read(), format="audio/mp3", autoplay=True)
                    tts_file.unlink(missing_ok=True)
                st.session_state.answer_start_time = time.time()
                st.session_state.question_audio_played = True

            st.info("–ì–æ–≤–æ—Ä–∏—Ç–µ –æ—Ç–≤–µ—Ç. –ù–∞–∂–º–∏—Ç–µ ¬´–î–∞–ª–µ–µ¬ª, –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ.")

            if st.button("–î–∞–ª–µ–µ"):
                abs_start = st.session_state.answer_start_time or time.time()
                abs_end = time.time()
                rel_start = max(0.0, abs_start - st.session_state.recording_started_at)
                rel_end = max(rel_start + 0.1, abs_end - st.session_state.recording_started_at)

                st.session_state.timestamps.append({
                    "index": q_idx,
                    "start": rel_start,
                    "end": rel_end
                })

                st.session_state.question_index += 1
                st.session_state.question_audio_played = False
                st.session_state.answer_start_time = None

                if st.session_state.question_index >= len(QUESTIONS):
                    st.session_state.video_ready = True

                st.rerun()
        else:
            st.session_state.video_ready = True
            st.rerun()

    # Processing after all questions are done and video is ready to be stopped
    if st.session_state.video_ready and not st.session_state.processing_started:
        st.success("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É **STOP** –ø–æ–¥ –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")
        
        if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"):
            # Check if the user has manually stopped the recording
            if not video_ctx.state.playing:
                st.session_state.processing_started = True
                st.rerun()
            else:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É **STOP** –ø–æ–¥ –≤–∏–¥–µ–æ.")

    # This block is for processing the results once the user has stopped the recording
    if st.session_state.processing_started:
        st.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã...")

        if not ffmpeg_available():
            st.error("FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
        elif not st.session_state.video_filename.exists():
            st.error("–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else:
            results = []
            for seg in st.session_state.timestamps:
                q_idx = seg["index"]
                audio_out = REC_DIR / f"answer_q{q_idx}_{uuid.uuid4().hex}.mp3"
                ok = cut_audio_segment(st.session_state.video_filename, seg["start"], seg["end"], audio_out)

                transcription_text = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ"
                if ok and audio_out.exists():
                    transcription_text = whisper_stt(audio_out)
                    audio_out.unlink(missing_ok=True)

                results.append({
                    "question": QUESTIONS[q_idx],
                    "start": seg["start"],
                    "end": seg["end"],
                    "transcription": transcription_text
                })

            st.session_state.transcriptions = results

            st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            for r in st.session_state.transcriptions:
                st.write(f"**–í–æ–ø—Ä–æ—Å:** {r['question']}")
                st.write(f"**–û—Ç–≤–µ—Ç:** {r['transcription']}")
                st.write(f"**–û—Ç—Ä–µ–∑–æ–∫:** {r['start']:.2f} ‚Äî {r['end']:.2f} —Å–µ–∫.")
                st.divider()

            st.header("–í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å")
            try:
                with open(st.session_state.video_filename, "rb") as f:
                    st.video(f.read())
                    f.seek(0)
                    st.download_button(
                        "–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (MP4)",
                        data=f.read(),
                        file_name=st.session_state.video_filename.name,
                        mime="video/mp4",
                    )
            except FileNotFoundError:
                st.error("–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏.")


            json_data = {
                "date": datetime.datetime.now().isoformat(),
                "video_file": st.session_state.video_filename.name,
                "answers": st.session_state.transcriptions
            }
            json_filename = st.session_state.video_filename.with_suffix(".json")
            
            # Write the dictionary to the file in JSON format
            with open(json_filename, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)

            # Show a success message
            st.success(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: {json_filename.name}")

            st.download_button(
                "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)",
                data=json.dumps(json_data, ensure_ascii=False, indent=2),
                file_name=st.session_state.video_filename.with_suffix(".json").name,
                mime="application/json",
            )
            
            if st.button("üîÑ –ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()
