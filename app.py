import streamlit as st
import json
import os
import datetime
import time
import uuid
import subprocess
from pathlib import Path
from gtts import gTTS
from openai import OpenAI
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from aiortc.contrib.media import MediaRecorder

# ========== CONFIG ==========
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
QUESTIONS = [
    "–ö–∞–∫ —Ç—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å —Å–≤–æ–π —É—Ä–æ–≤–µ–Ω—å —Å—Ç—Ä–µ—Å—Å–∞ –æ—Ç 1 –¥–æ 10?",
    "–ö–∞–∫ —Ç—ã –æ–±—ã—á–Ω–æ —Å–Ω–∏–º–∞–µ—à—å —Å—Ç—Ä–µ—Å—Å: –∞–ª–∫–æ–≥–æ–ª—å, —Å–∏–≥–∞—Ä–µ—Ç—ã, —Ñ–∏–∑–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –µ–¥–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–µ –∏–≥—Ä—ã, –æ–±—â–µ–Ω–∏–µ —Å –¥—Ä—É–∑—å—è–º–∏?",
]

REC_DIR = Path("recordings")
REC_DIR.mkdir(exist_ok=True)

# ========== SESSION STATE INITIALIZATION ==========
defaults = {
    "start_interview": False,
    "questions_started": False,
    "question_index": 0,
    "question_audio_played": False,
    "answer_start_time": None,
    "timestamps": [],
    "recording_started_at": None,
    "video_ready": False,
    "video_filename": REC_DIR / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4",
    "transcriptions": [],
    "recorder_stopped": False,
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ========== HELPERS ==========
def text_to_speech(text, filename):
    try:
        tts = gTTS(text=text, lang="ru")
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

def whisper_stt(audio_path: Path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )
        return transcription.text
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {str(e)}"

def ffmpeg_available():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except Exception:
        return False

def cut_audio_segment(video_path: Path, start: float, end: float, output_path: Path):
    try:
        cmd = [
            "ffmpeg", "-y",
            "-i", str(video_path),
            "-ss", f"{start}",
            "-to", f"{end}",
            "-vn",
            "-acodec", "libmp3lame",
            str(output_path)
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return True
    except subprocess.CalledProcessError as e:
        stderr = e.stderr.decode() if e.stderr else str(e)
        st.error(f"FFmpeg error while cutting audio: {stderr}")
        return False

# ========== UI ==========
st.title("–ê–Ω–∞–ª–∏–∑ –≤–∞—à–µ–≥–æ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è")

if not st.session_state.start_interview:
    st.info(
        "üìπ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n\n"
        "1. –ù–∞–∂–º–∏—Ç–µ **–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é** ‚Äî —ç—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –∫–∞–º–µ—Ä—É –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –Ω–∞—á–Ω—ë—Ç –∑–∞–ø–∏—Å—å.\n"
        "2. –ù–∞–∂–º–∏—Ç–µ **‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã** ‚Äî –≤–æ–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –∑–∞—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –≤—Å–ª—É—Ö.\n"
        "3. –ü–æ—Å–ª–µ –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç–≤–µ—á–∞–π—Ç–µ; –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–∂–º–∏—Ç–µ **–î–∞–ª–µ–µ**.\n"
        "4. –ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –ø–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É.\n\n"
        "**–í–∞–∂–Ω–æ:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –±—Ä–∞—É–∑–µ—Ä —Ä–∞–∑—Ä–µ—à–∏–ª –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∏ –∫–∞–º–µ—Ä–µ."
    )
    if st.button("üé¨ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é"):
        st.session_state.start_interview = True
        st.rerun()
else:
    video_filename_path = str(st.session_state.video_filename)

    video_ctx = webrtc_streamer(
        key="interview-video",
        mode=WebRtcMode.SENDRECV,
        media_stream_constraints={"video": True, "audio": True},
        in_recorder_factory=lambda: MediaRecorder(video_filename_path, format="mp4"),
    )

    # –§–∏–∫—Å: –∑–∞–ø–æ–º–∏–Ω–∞–µ–º —Å—Ç–∞—Ä—Ç –∑–∞–ø–∏—Å–∏
    if video_ctx.state.playing and st.session_state.recording_started_at is None:
        st.session_state.recording_started_at = time.time()
        st.success("–ó–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –Ω–∞—á–∞–ª–∞—Å—å.")

    # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–æ–ø—Ä–æ—Å–æ–≤
    if video_ctx.state.playing and not st.session_state.questions_started:
        if st.button("‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã"):
            st.session_state.questions_started = True
            st.session_state.question_audio_played = False
            st.rerun()

    # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –≤–æ–ø—Ä–æ—Å–æ–≤
    if st.session_state.questions_started and not st.session_state.video_ready:
        if st.session_state.question_index < len(QUESTIONS):
            q_idx = st.session_state.question_index
            current_question = QUESTIONS[q_idx]
            st.write(f"–í–æ–ø—Ä–æ—Å {q_idx + 1}: {current_question}")

            if not st.session_state.question_audio_played:
                tts_file = REC_DIR / f"q_{q_idx}_{uuid.uuid4().hex}.mp3"
                if text_to_speech(current_question, str(tts_file)):
                    with open(tts_file, "rb") as f:
                        st.audio(f.read(), format="audio/mp3", autoplay=True)
                    tts_file.unlink(missing_ok=True)
                st.session_state.answer_start_time = time.time()
                st.session_state.question_audio_played = True

            st.info("–ì–æ–≤–æ—Ä–∏—Ç–µ –æ—Ç–≤–µ—Ç. –ù–∞–∂–º–∏—Ç–µ ¬´–î–∞–ª–µ–µ¬ª, –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ.")

            if st.button("–î–∞–ª–µ–µ"):
                abs_start = st.session_state.answer_start_time or time.time()
                abs_end = time.time()
                rel_start = max(0.0, abs_start - st.session_state.recording_started_at)
                rel_end = max(rel_start + 0.1, abs_end - st.session_state.recording_started_at)

                st.session_state.timestamps.append({
                    "index": q_idx,
                    "start": rel_start,
                    "end": rel_end
                })

                st.session_state.question_index += 1
                st.session_state.question_audio_played = False
                st.session_state.answer_start_time = None

                if st.session_state.question_index >= len(QUESTIONS):
                    st.session_state.video_ready = True

                st.rerun()
        else:
            st.session_state.video_ready = True
            st.rerun()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    if st.session_state.video_ready:
        st.success("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å...")

        # –§–∏–∫—Å: —è–≤–Ω–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MediaRecorder
        if not st.session_state.recorder_stopped:
            if hasattr(video_ctx, "in_recorder") and video_ctx.in_recorder:
                try:
                    video_ctx.in_recorder.stop()
                    time.sleep(2)  # –¥–∞—ë–º –≤—Ä–µ–º—è –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∞–º MP4
                    st.session_state.recorder_stopped = True
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: {e}")

        if not ffmpeg_available():
            st.error("FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ.")
        elif not st.session_state.video_filename.exists():
            st.error("–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else:
            st.info("–í—ã—Ä–µ–∑–∞–µ–º –æ—Ç–≤–µ—Ç—ã –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ...")

            results = []
            for seg in st.session_state.timestamps:
                q_idx = seg["index"]
                audio_out = REC_DIR / f"answer_q{q_idx}_{uuid.uuid4().hex}.mp3"
                ok = cut_audio_segment(st.session_state.video_filename, seg["start"], seg["end"], audio_out)

                transcription_text = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ"
                if ok and audio_out.exists():
                    transcription_text = whisper_stt(audio_out)
                    audio_out.unlink(missing_ok=True)

                results.append({
                    "question": QUESTIONS[q_idx],
                    "start": seg["start"],
                    "end": seg["end"],
                    "transcription": transcription_text
                })

            st.session_state.transcriptions = results

            st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            for r in st.session_state.transcriptions:
                st.write(f"**–í–æ–ø—Ä–æ—Å:** {r['question']}")
                st.write(f"**–û—Ç–≤–µ—Ç:** {r['transcription']}")
                st.write(f"**–û—Ç—Ä–µ–∑–æ–∫:** {r['start']:.2f} ‚Äî {r['end']:.2f}")
                st.divider()

            st.header("–í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å")
            with open(st.session_state.video_filename, "rb") as f:
                st.video(f.read())
                f.seek(0)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (MP4)",
                    data=f.read(),
                    file_name=st.session_state.video_filename.name,
                    mime="video/mp4",
                )

            json_data = {
                "date": datetime.datetime.now().isoformat(),
                "video_file": st.session_state.video_filename.name,
                "answers": st.session_state.transcriptions
            }
            st.download_button(
                "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)",
                data=json.dumps(json_data, ensure_ascii=False, indent=2),
                file_name=st.session_state.video_filename.with_suffix(".json").name,
                mime="application/json",
            )

            if st.button("üîÑ –ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()
