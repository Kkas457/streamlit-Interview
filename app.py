import streamlit as st
import json
import os
import datetime
import io
from gtts import gTTS
from openai import OpenAI
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from aiortc.contrib.media import MediaRecorder
from pathlib import Path
from streamlit_mic_recorder import mic_recorder
import time

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –í–æ–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
QUESTIONS = [
    "–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–µ–±–µ.",
    "–ö–∞–∫–æ–≤—ã –≤–∞—à–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã?",
    "–û–ø–∏—à–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–π –ø—Ä–æ–µ–∫—Ç, –Ω–∞–¥ –∫–æ—Ç–æ—Ä—ã–º –≤—ã —Ä–∞–±–æ—Ç–∞–ª–∏.",
    "–ü–æ—á–µ–º—É –≤—ã —Ö–æ—Ç–∏—Ç–µ –ø–æ–ª—É—á–∏—Ç—å —ç—Ç—É –¥–æ–ª–∂–Ω–æ—Å—Ç—å?",
    "–ì–¥–µ –≤—ã –≤–∏–¥–∏—Ç–µ —Å–µ–±—è —á–µ—Ä–µ–∑ –ø—è—Ç—å –ª–µ—Ç?"
]

# –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏
if "start_interview" not in st.session_state:
    st.session_state.start_interview = False
if "question_index" not in st.session_state:
    st.session_state.question_index = 0
if "transcriptions" not in st.session_state:
    st.session_state.transcriptions = []
if "video_ready" not in st.session_state:
    st.session_state.video_ready = False

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∑–∞–ø–∏—Å–µ–π
REC_DIR = Path("recordings")
REC_DIR.mkdir(exist_ok=True)

if "rec_filename" not in st.session_state:
    prefix = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    st.session_state.rec_filename = REC_DIR / f"{prefix}.mp4"

out_path = st.session_state.rec_filename

# –¢–µ–∫—Å—Ç –≤ —Ä–µ—á—å
def text_to_speech(text, filename):
    try:
        tts = gTTS(text=text, lang="ru")
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

# –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ Whisper
def whisper_stt(question_index):
    audio = mic_recorder(
        start_prompt="üéôÔ∏è –ì–æ–≤–æ—Ä–∏—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç",
        stop_prompt="‚èπÔ∏è –°—Ç–æ–ø",
        format="webm",
        key=f"whisper_{question_index}"
    )
    if audio:
        audio_bio = io.BytesIO(audio["bytes"])
        audio_bio.name = "audio.webm"
        try:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_bio,
                language="ru"
            )
            return transcription.text
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"
    return None

# –§–∞–±—Ä–∏–∫–∞ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–µ–æ+–∞—É–¥–∏–æ
def in_recorder_factory():
    return MediaRecorder(str(out_path), format="mp4")

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("–¢—Ä–µ–Ω–∞–∂—ë—Ä —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–π")

# JavaScript –¥–ª—è –∞–≤—Ç–æ–∫–ª–∏–∫–∞ –∫–Ω–æ–ø–∫–∏ "START"
st.markdown("""
<script>
    document.addEventListener('DOMContentLoaded', function() {
        setTimeout(function() {
            const startButton = Array.from(document.querySelectorAll('button')).find(
                btn => btn.textContent.trim() === 'START'
            );
            if (startButton) {
                startButton.click();
            }
        }, 500); // –ó–∞–¥–µ—Ä–∂–∫–∞ 500 –º—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ DOM
    });
</script>
""", unsafe_allow_html=True)

# –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤—å—é –µ—â—ë –Ω–µ –Ω–∞—á–∞–ª–æ—Å—å
if not st.session_state.start_interview:
    st.info("–ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –∏ –∏–Ω—Ç–µ—Ä–≤—å—é.")
    if st.button("üé¨ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é"):
        st.session_state.start_interview = True
        st.rerun()
else:
    # –ó–∞–ø—É—Å–∫ WebRTC –∑–∞–ø–∏—Å–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å—ã –µ—â—ë –Ω–µ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å
    if st.session_state.question_index < len(QUESTIONS):
        ctx = webrtc_streamer(
            key="interview-recorder",
            mode=WebRtcMode.SENDRECV,
            media_stream_constraints={"video": True, "audio": True},
            in_recorder_factory=in_recorder_factory,
        )

        current_question = QUESTIONS[st.session_state.question_index]
        st.write(f"–í–æ–ø—Ä–æ—Å {st.session_state.question_index + 1}: {current_question}")

        audio_file = f"question_{st.session_state.question_index}.mp3"
        if text_to_speech(current_question, audio_file):
            with open(audio_file, "rb") as f:
                st.audio(f.read(), format="audio/mp3", autoplay=True)

        transcription = whisper_stt(st.session_state.question_index)
        if transcription:
            st.session_state.transcriptions.append({
                "question": current_question,
                "transcription": transcription,
                "timestamp": datetime.datetime.now().isoformat()
            })

            st.session_state.question_index += 1
            if os.path.exists(audio_file):
                os.remove(audio_file)

            if st.session_state.question_index >= len(QUESTIONS):
                # –ñ–¥—ë–º —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤
                for _ in range(15):
                    if out_path.exists() and out_path.stat().st_size > 100_000:
                        st.session_state.video_ready = True
                        break
                    time.sleep(0.3)
                st.rerun()
            else:
                st.rerun()

    # –ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    if st.session_state.video_ready:
        st.subheader("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        for item in st.session_state.transcriptions:
            st.write(f"**–í–æ–ø—Ä–æ—Å:** {item['question']}")
            st.write(f"**–í–∞—à –æ—Ç–≤–µ—Ç:** {item['transcription']}")
            st.write(f"**–í—Ä–µ–º—è:** {item['timestamp']}")
            st.write("---")

        st.subheader("–í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å —Å –∞—É–¥–∏–æ")
        st.video(str(out_path))
        st.download_button(
            "–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (MP4)",
            data=out_path.read_bytes(),
            file_name=out_path.name,
            mime="video/mp4",
        )

        results = {
            "–¥–∞—Ç–∞_–∏–Ω—Ç–µ—Ä–≤—å—é": datetime.datetime.now().isoformat(),
            "–≤–æ–ø—Ä–æ—Å—ã": st.session_state.transcriptions
        }
        json_filename = f"—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã_–∏–Ω—Ç–µ—Ä–≤—å—é_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_filename, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        with open(json_filename, "rb") as f:
            st.download_button("–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)", f, json_filename, "application/json")

        if st.button("üîÑ –ù–∞—á–∞—Ç—å –Ω–æ–≤–æ–µ –∏–Ω—Ç–µ—Ä–≤—å—é"):
            st.session_state.start_interview = False
            st.session_state.question_index = 0
            st.session_state.transcriptions = []
            st.session_state.video_ready = False
            st.session_state.rec_filename = REC_DIR / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
            st.rerun()