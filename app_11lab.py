import streamlit as st
import json
import os
import datetime
import time
import uuid
import subprocess
from pathlib import Path
from gtts import gTTS
from openai import OpenAI
from streamlit_webrtc import webrtc_streamer, WebRtcMode
from aiortc.contrib.media import MediaRecorder

# Import the ElevenLabs library
from elevenlabs.client import ElevenLabs
# ========== CONFIG ==========
# You will now need both OpenAI and ElevenLabs API keys
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
elevenlabs_client = ElevenLabs(api_key=os.getenv("eleven_lab_api"))

QUESTIONS = [
             '–î–æ–±—Ä—ã–π –¥–µ–Ω—å, –∫–∞–∫ —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—à—å?',
             '–í–∞—à –§–ò–û', 
             '–¥–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è', 
             '–º–µ—Å—Ç–æ —Ä–æ–∂–¥–µ–Ω–∏—è –∏ –º–µ—Å—Ç–æ–∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞',
             '–µ—Å—Ç—å –ª–∏ —É —Ç–µ–±—è —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è? –ö–∞–∫–∏–µ?',
             '–í—ã –≤–æ—Å–ø–∏—Ç—ã–≤–∞–ª–∏—Å—å –≤ –ø–æ–ª–Ω–æ–π/–Ω–µ–ø–æ–ª–Ω–æ–π —Å–µ–º—å–µ',
             '–ï—Å—Ç—å –ª–∏ —É–º–µ—Ä—à–∏–µ —Å—Ä–µ–¥–∏ –±–ª–∏–∑–∫–∏—Ö —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ ? (–∫—Ç–æ, –≥–æ–¥ —Å–º–µ—Ä—Ç–∏, –ø—Ä–∏—á–∏–Ω–∞)',
             '–§–ò–û  –æ—Ç—Ü–∞, –≤–æ–∑—Ä–∞—Å—Ç,–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã, –≤–∞—à–∞ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è',
             '–§–ò–û –º–∞—Ç–µ—Ä–∏, –≤–æ–∑—Ä–∞—Å—Ç,–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã, –≤–∞—à–∞ –≤–∑–∞–∏–º–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è',
             '–±—Ä–∞—Ç—å—è –∏ —Å–µ—Å—Ç—Ä—ã –§–ò–û,–≤–æ–∑—Ä–∞—Å—Ç',
             '–ë—ã–≤–∞–ª–∏ –ª–∏ —É –í–∞—Å —Å–ª—É—á–∞–∏ –ø–æ–±–µ–≥–æ–≤ –∏–∑ –¥–æ–º–∞? ',
             '–ï—Å—Ç—å –ª–∏ –≤ –≥–æ—Ä–æ–¥–µ –ê—Å—Ç–∞–Ω–∞ —Ä–æ–¥—Å—Ç–≤–µ–Ω–∏–∫–∏ –∏–ª–∏ –∑–Ω–∞–∫–æ–º—ã–µ (—Ñ–∏–æ –∏ –∞–¥—Ä–µ—Å)',
             '–±—ã–ª–∏ –ª–∏ —Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–∞ –∏–ª–∏ —Å—É–∏—Ü–∏–¥–∞–ª—å–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏ —É —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ ',
             '–∏–º–µ–ª–∏—Å—å –ª–∏ —É –í–∞—Å –≤ –ø—Ä–æ—à–ª–æ–º —Å—É–∏—Ü–∏–¥–∞–ª—å–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏/–º—ã—Å–ª–∏ ',
             '–ë—ã–ª–∏ –ª–∏ –≤ –í–∞—à–µ–π —Å–µ–º—å–µ –∏–ª–∏ —É –±–ª–∏–∂–∞–π—à–∏—Ö —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤: / –∞–ª–∫–æ–≥–æ–ª–∏–∑–º /–Ω–∞—Ä–∫–æ–º–∞–Ω–∏—è/  —Å—É–¥–∏–º–æ—Å—Ç—å /–Ω–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–µ—Ä–≤–Ω–æ-–ø—Å–∏—Ö–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è ',
             '–ë—ã–ª–∏ –ª–∏ —É –í–∞—Å –¥–æ –∞—Ä–º–∏–∏ —Ñ–∞–∫—Ç—ã: / –∞–ª–∫–æ–≥–æ–ª–∏–∑–º–∞ /–Ω–∞—Ä–∫–æ–º–∞–Ω–∏–∏ / —Å—É–¥–∏–º–æ—Å—Ç–∏ / –Ω–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –Ω–µ—Ä–≤–Ω–æ-–ø—Å–∏—Ö–∏—á–µ—Å–∫–∏–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è, /–∏–≥—Ä–æ–º–∞–Ω–∏—è ',
             '–ò–º–µ–µ—à—å –ª–∏ —Ç—ã —Ç—è–∂—ë–ª—ã–µ –Ω–∞—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è? (–ù–∞–ø—Ä–∏–º–µ—Ä, –æ–Ω–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ, –¥—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏—è, –≥–∏–ø–µ—Ä—Ç–æ–Ω–∏—è –ò —Å–µ—Ä–¥–µ—á–Ω—ã–µ, —Ç.–¥.)',
             '–ë—ã–ª–∏ –ª–∏ —É –±–ª–∏–∂–∞–π—à–∏—Ö  —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ –∏–ª–∏ —É –í–∞—Å —Å—É–¥–æ—Ä–æ–∂–Ω—ã–µ –ø—Ä–∏–ø–∞–¥–∫–∏',
             '–ë—ã–ª–æ –ª–∏ —É –≤–∞—Å –Ω–æ—á–Ω–æ–µ –Ω–µ–¥–µ—Ä–∂–∞–Ω–∏–µ –º–æ—á–∏? - / –í –∫–∞–∫–æ–º –≤–æ–∑—Ä–∞—Å—Ç–µ?',
             '–ö–µ–º —Ä–∞–±–æ—Ç–∞–ª –¥–æ –∞—Ä–º–∏–∏, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏?',
             '–ñ–µ–ª–∞–µ—Ç–µ –ª–∏ –≤—ã –ø—Ä–æ—Ö–æ–¥–∏—Ç—å –≤–æ–µ–Ω–Ω—É—é —Å–ª—É–∂–±—É (–¥–∞/–Ω–µ—Ç, –ø—Ä–∏—á–∏–Ω–∞ )',
             '–≤ —á–µ–º –¥–ª—è —Ç–µ–±—è –±—É–¥–µ—Ç —Ç—Ä—É–¥–Ω–æ—Å—Ç—å –≤–æ–∏–Ω—Å–∫–æ–π —Å–ª—É–∂–±—ã: –±–µ—Å–ø—Ä–∏–∫–æ—Å–ª–æ–≤–Ω–æ–µ –ø–æ–¥—á–∏–Ω–µ–Ω–∏–µ/—Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏/—É–¥–∞–ª–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç –¥–æ–º–∞/–≤—ã—Å–æ–∫–∞—è –ª–∏—á–Ω–∞—è –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å/–ø—Ä–µ–æ–¥–æ–ª–µ–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–≤—ã—á–µ–∫/–¥—Ä—É–≥–æ–µ ',
             '–∫–∞–∫—É—é —Ä–µ–ª–∏–≥–∏—é –∏—Å–ø–æ–≤–µ–¥–∞–µ—à—å',
             '–∫–∞–∫ —á–∞—Å—Ç–æ —Ö–æ–¥–∏—à—å –≤ –º–µ—á–µ—Ç—å/—Ü–µ—Ä–∫–æ–≤—å',
             '–ø—Ä–∞–∑–¥–Ω—É–µ—Ç–µ –ª–∏ –≤—ã —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–∏?–•–æ–¥–∏—Ç–µ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–æ—Ä–∂–µ—Å—Ç–≤–∞ (–¥–Ω–∏ —Ä–æ–∂–¥–µ–Ω–∏—è, —Å–≤–∞–¥—å–±—ã)',
             '–µ—Å—Ç—å –ª–∏ –¥–µ–≤—É—à–∫–∞? –ù–∞—Å–∫–æ–ª—å–∫–æ –±–ª–∏–∑–∫–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏—è –ø–æ —à–∫–∞–ª–µ –æ—Ç 1 –¥–æ  5',
             '–¥–µ–ª–∞–µ—à—å –ª–∏ —Å—Ç–∞–≤–∫–∏ –≤ –±—É–∫–º–µ–∫–µ—Ä—Å–∫–∏—Ö –∫–æ–Ω—Ç–æ—Ä–∞—Ö –∏–ª–∏ –æ–Ω –ª–∞–π–Ω ',
             '–µ—Å—Ç—å —É —Ç–µ–±—è –∫—Ä–µ–¥–∏—Ç—ã/–∑–∞–π–º—ã (—Å–∫–æ–ª—å–∫–æ, –Ω–∞ –∫–∞–∫—É—é —Å—É–º–º—É, –∫—Ç–æ –æ–ø–ª–∞—á–∏–≤–∞–µ—Ç)',
             '–ü—Ä–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–∏ –í–í–ö –≤ –î–î–û –ø–æ–ª–Ω–æ—Å—Ç—å—é –ª–∏ –í—ã –ø—Ä–æ—à–ª–∏ –æ–±—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —É –≤—Ä–∞—á–µ–π, –µ—Å—Ç—å –ª–∏ —Ñ–∞–∫—Ç—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –í–∞—à–µ–≥–æ –∑–¥–æ—Ä–æ–≤—å—è (–¥–∏–∞–≥–Ω–æ–∑—ã –ø–æ –∫–æ—Ç–æ—Ä—ã–º —Ä–∞–Ω–µ–µ –í–∞—Å –Ω–µ –±—Ä–∞–ª–∏ –Ω–∞ —Å–ª—É–∂–±—É), –æ –∫–æ—Ç–æ—Ä—ã—Ö –í—ã –Ω–µ —Å–∫–∞–∑–∞–ª–∏ –≤–∞—à–µ–º—É —Å—Ç–∞—Ä—à–µ–º—É'
             ]

REC_DIR = Path("recordings")
REC_DIR.mkdir(exist_ok=True)

# ========== SESSION STATE INITIALIZATION ==========
defaults = {
    "start_interview": False,
    "questions_started": False,
    "question_index": 0,
    "question_audio_played": False,
    "answer_start_time": None,
    "timestamps": [],
    "recording_started_at": None,
    "video_ready": False,
    "video_filename": REC_DIR / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4",
    "transcriptions": [],
    "recorder_stopped": False,
    "processing_started": False,
}
for k, v in defaults.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ========== HELPERS ==========
def text_to_speech(text, filename):
    try:
        tts = gTTS(text=text, lang="ru")
        tts.save(filename)
        return filename
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None
    
# Updated STT function to use ElevenLabs
def elevenlabs_stt(audio_path: Path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = elevenlabs_client.speech_to_text.convert(
                file=audio_file,
                model_id="scribe_v1",
                tag_audio_events=True,
                diarize=True,
                language_code='rus',  # Specify the language code for Russian
            )
        return transcript.text
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {str(e)}"

def ffmpeg_available():
    try:
        subprocess.run(["ffmpeg", "-version"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
        return True
    except Exception:
        return False

def cut_audio_segment(video_path: Path, start: float, end: float, output_path: Path):
    try:
        # Use an absolute path for safety
        output_path_wav = output_path.with_suffix(".wav")
        cmd = [
            "ffmpeg", "-y",
            "-i", str(video_path),
            "-ss", f"{start}",
            "-to", f"{end}",
            "-vn",
            "-acodec", "pcm_s16le", # PCM signed 16-bit little-endian is a standard WAV codec
            "-ar", "16000",          # Set sample rate to 16 kHz, which is standard for speech recognition
            "-ac", "1",              # Set to mono audio
            str(output_path_wav)
        ]
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return output_path_wav
    except subprocess.CalledProcessError as e:
        stderr = e.stderr.decode() if e.stderr else str(e)
        st.error(f"FFmpeg error while cutting audio: {stderr}")
        return None

# ========== UI ==========
st.title("interview-psychologist")

if not st.session_state.start_interview:
    st.info(
        "üìπ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n\n"
        "1. –ù–∞–∂–º–∏—Ç–µ **–ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é** ‚Äî —ç—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –∫–∞–º–µ—Ä—É –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –Ω–∞—á–Ω—ë—Ç –∑–∞–ø–∏—Å—å.\n"
        "2. –ù–∞–∂–º–∏—Ç–µ **‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã** ‚Äî –≤–æ–ø—Ä–æ—Å—ã –±—É–¥—É—Ç –∑–∞—á–∏—Ç—ã–≤–∞—Ç—å—Å—è –≤—Å–ª—É—Ö.\n"
        "3. –ü–æ—Å–ª–µ –≤–æ–ø—Ä–æ—Å–∞ –æ—Ç–≤–µ—á–∞–π—Ç–µ; –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ ‚Äî –Ω–∞–∂–º–∏—Ç–µ **–î–∞–ª–µ–µ**.\n"
        "4. –ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É ¬´**STOP**¬ª –ø–æ–¥ –≤–∏–¥–µ–æ, –∑–∞—Ç–µ–º **–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã**.\n"
        "5. –í—ã –ø–æ–ª—É—á–∏—Ç–µ –≤–∏–¥–µ–æ –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É.\n\n"
        "**–í–∞–∂–Ω–æ:** –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–∞—à –±—Ä–∞—É–∑–µ—Ä —Ä–∞–∑—Ä–µ—à–∏–ª –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∏ –∫–∞–º–µ—Ä–µ."
    )
    if st.button("üé¨ –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é"):
        st.session_state.start_interview = True
        st.rerun()
else:
    video_filename_path = str(st.session_state.video_filename)

    # Use 'sendonly' for video and 'sendrecv' for audio to prevent issues
    video_ctx = webrtc_streamer(
    key="interview-video",
    mode=WebRtcMode.SENDRECV,
    media_stream_constraints={
        "video": {"width": 640, "height": 480, "frameRate": 15},
        "audio": True
    },
    # ‚úÖ FIXED: Record the outgoing (looped-back) stream which has audio.
    out_recorder_factory=lambda: MediaRecorder(video_filename_path, format="mp4"),
    )

    if video_ctx.state.playing and st.session_state.recording_started_at is None:
        st.session_state.recording_started_at = time.time()
        st.success("–ó–∞–ø–∏—Å—å –≤–∏–¥–µ–æ –Ω–∞—á–∞–ª–∞—Å—å.")

    # Show "Start Questions" button only when video is playing
    if video_ctx.state.playing and not st.session_state.questions_started and not st.session_state.video_ready:
        if st.button("‚ñ∂ –ù–∞—á–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã"):
            st.session_state.questions_started = True
            st.session_state.question_audio_played = False
            st.rerun()

    if st.session_state.questions_started and not st.session_state.video_ready:
        if st.session_state.question_index < len(QUESTIONS):
            q_idx = st.session_state.question_index
            current_question = QUESTIONS[q_idx]
            st.write(f"–í–æ–ø—Ä–æ—Å {q_idx + 1}: {current_question}")

            if not st.session_state.question_audio_played:
                tts_file = REC_DIR / f"q_{q_idx}_{uuid.uuid4().hex}.mp3"
                if text_to_speech(current_question, str(tts_file)):
                    with open(tts_file, "rb") as f:
                        st.audio(f.read(), format="audio/mp3", autoplay=True)
                    tts_file.unlink(missing_ok=True)
                st.session_state.answer_start_time = time.time()
                st.session_state.question_audio_played = True

            st.info("–ì–æ–≤–æ—Ä–∏—Ç–µ –æ—Ç–≤–µ—Ç. –ù–∞–∂–º–∏—Ç–µ ¬´–î–∞–ª–µ–µ¬ª, –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—Ç–µ.")

            if st.button("–î–∞–ª–µ–µ"):
                abs_start = st.session_state.answer_start_time or time.time()
                abs_end = time.time()
                rel_start = max(0.0, abs_start - st.session_state.recording_started_at)
                rel_end = max(rel_start + 0.1, abs_end - st.session_state.recording_started_at)

                st.session_state.timestamps.append({
                    "index": q_idx,
                    "start": rel_start,
                    "end": rel_end
                })

                st.session_state.question_index += 1
                st.session_state.question_audio_played = False
                st.session_state.answer_start_time = None

                if st.session_state.question_index >= len(QUESTIONS):
                    st.session_state.video_ready = True

                st.rerun()
        else:
            st.session_state.video_ready = True
            st.rerun()

    # Processing after all questions are done and video is ready to be stopped
    if st.session_state.video_ready and not st.session_state.processing_started:
        st.success("–ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É **STOP** –ø–æ–¥ –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")
        
        if st.button("–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"):
            # Check if the user has manually stopped the recording
            if not video_ctx.state.playing:
                st.session_state.processing_started = True
                st.rerun()
            else:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫—Ä–∞—Å–Ω—É—é –∫–Ω–æ–ø–∫—É **STOP** –ø–æ–¥ –≤–∏–¥–µ–æ.")

    # This block is for processing the results once the user has stopped the recording
    if st.session_state.processing_started:
        st.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∏–¥–µ–æ –∏ —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç—ã...")

        if not ffmpeg_available():
            st.error("FFmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
        elif not st.session_state.video_filename.exists():
            st.error("–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        else:
            results = []
            progress_bar = st.progress(0)
            for i, seg in enumerate(st.session_state.timestamps):
                q_idx = seg["index"]
                audio_out_path = REC_DIR / f"answer_q{q_idx}_{uuid.uuid4().hex}.wav"
                
                # Call the updated function which returns the path if successful
                ok = cut_audio_segment(st.session_state.video_filename, seg["start"], seg["end"], audio_out_path)

                transcription_text = "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ"
                if ok and ok.exists():
                    # Call the new ElevenLabs STT function
                    transcription_text = elevenlabs_stt(ok)
                    ok.unlink(missing_ok=True) # Clean up the temporary WAV file

                results.append({
                    "question": QUESTIONS[q_idx],
                    "start": seg["start"],
                    "end": seg["end"],
                    "transcription": transcription_text
                })
                
                progress_bar.progress((i + 1) / len(st.session_state.timestamps))
            
            st.session_state.transcriptions = results

            st.header("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            for r in st.session_state.transcriptions:
                st.write(f"**–í–æ–ø—Ä–æ—Å:** {r['question']}")
                st.write(f"**–û—Ç–≤–µ—Ç:** {r['transcription']}")
                st.write(f"**–û—Ç—Ä–µ–∑–æ–∫:** {r['start']:.2f} ‚Äî {r['end']:.2f} —Å–µ–∫.")
                st.divider()

            st.header("–í–∏–¥–µ–æ–∑–∞–ø–∏—Å—å")
            try:
                with open(st.session_state.video_filename, "rb") as f:
                    st.video(f.read())
                    f.seek(0)
                    st.download_button(
                        "–°–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (MP4)",
                        data=f.read(),
                        file_name=st.session_state.video_filename.name,
                        mime="video/mp4",
                    )
            except FileNotFoundError:
                st.error("–í–∏–¥–µ–æ—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏.")


            json_data = {
                "date": datetime.datetime.now().isoformat(),
                "video_file": st.session_state.video_filename.name,
                "answers": st.session_state.transcriptions
            }
            json_filename = st.session_state.video_filename.with_suffix(".json")
            
            # Write the dictionary to the file in JSON format
            with open(json_filename, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)

            # Show a success message
            st.success(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª: {json_filename.name}")

            st.download_button(
                "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)",
                data=json.dumps(json_data, ensure_ascii=False, indent=2),
                file_name=st.session_state.video_filename.with_suffix(".json").name,
                mime="application/json",
            )
            
            if st.button("üîÑ –ù–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ"):
                for key in list(st.session_state.keys()):
                    del st.session_state[key]
                st.rerun()
